{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import pandas as pd\n",
    "import ncl.sqlsnippets as snips\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "\n",
    "#Import env\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import runtime settings from .env file\n",
    "def import_settings():\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    return {\n",
    "        \"FIN_YEAR\": json.loads(getenv(\"FIN_YEAR\")),\n",
    "        \"FIN_MONTH\": json.loads(getenv(\"FIN_MONTH\")),\n",
    "        \"PROCEDURES\": json.loads(getenv(\"PROCEDURES\")),\n",
    "\n",
    "        \"SQL_ADDRESS\": getenv(\"SQL_ADDRESS\"),\n",
    "        \"SQL_DATABASE\": getenv(\"SQL_DATABASE\"),\n",
    "        \"SQL_SCHEMA\": getenv(\"SQL_SCHEMA\"),\n",
    "        \"SQL_TABLE\": getenv(\"SQL_TABLE\"),\n",
    "\n",
    "        \"OUTPUT\": getenv(\"OUTPUT\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert an array into a SQL set (as a string)\n",
    "def array_to_set (arr):\n",
    "\n",
    "    #Initalise string\n",
    "    str_set = \"(\"\n",
    "\n",
    "    #Add each item of the array to the set string\n",
    "    for item in arr:\n",
    "        str_set += f\"'{item}', \"\n",
    "\n",
    "    #Close the brackets and remove the comma from the last item added\n",
    "    str_set = str_set[:-2] + \")\"\n",
    "\n",
    "    return str_set\n",
    "\n",
    "#Generate the where clause based on the scope of the execution (.env settings)\n",
    "def load_ref_where (fin_year, fin_month):\n",
    "\n",
    "    #Array of the clauses because it is not guaranteed they will be used\n",
    "    clause = [\"WHERE\", \"AND\"]\n",
    "    #Flag to check if the year clause is not blank when processing the month clause\n",
    "    idx = 0\n",
    "    #String to build where clause\n",
    "    sql_where = \"\"\n",
    "\n",
    "    if fin_year != []:\n",
    "        #Convert array to set format\n",
    "        year_set = array_to_set(fin_year)\n",
    "        #Build where clause\n",
    "        sql_where += f\"{clause[idx]} opcs.Year IN {year_set}\\nAND icd.Year IN {year_set}\\n\"\n",
    "        #Update idx flag\n",
    "        idx += 1\n",
    "\n",
    "    if fin_month != []:\n",
    "        #Convert array to set format\n",
    "        month_set = array_to_set(fin_month)\n",
    "        #Build where clause\n",
    "        sql_where += f\"{clause[idx]} opcs.Fin_Month IN {month_set}\\nAND icd.Fin_Month IN {month_set}\"\n",
    "\n",
    "    return sql_where\n",
    "\n",
    "#Load the base reference table to apply the where clause to\n",
    "def load_ref_base (fin_year, fin_month):\n",
    "    #Path to base reference file\n",
    "    path_base = \"./data/base_ref_table.sql\"\n",
    "    \n",
    "    #Read sql in the file\n",
    "    with open(path_base, 'r') as sql_file:\n",
    "        sql_string = sql_file.read()\n",
    "\n",
    "    #Derrive the where clause\n",
    "    where_clause = load_ref_where (fin_year, fin_month)\n",
    "\n",
    "    #Append the where clause\n",
    "    sql_string += f\"\\n\\n{where_clause}\"\n",
    "\n",
    "    #Wrap the query (So it is easier to add the where clause for the procedure)\n",
    "    sql_string = f\"SELECT Year, Fin_month, PRIMARYKEY_ID AS eID FROM (\\n{sql_string}\\n\\n) base\\n\\n\"\n",
    "\n",
    "    return sql_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a given procedure\n",
    "def find_procedure (id):\n",
    "    path_procedure = \"./data/procedures\"\n",
    "\n",
    "    #Initalise match\n",
    "    matching_file = False\n",
    "\n",
    "    #For each file in the procedure directory\n",
    "    for root, dirs, files in os.walk(path_procedure):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                #Open the json file\n",
    "                with open(file_path, \"r\") as json_file:\n",
    "                    try:\n",
    "                        #Load the data\n",
    "                        data = json.load(json_file)\n",
    "\n",
    "                        #Check if it contains the id\n",
    "                        if isinstance(data, dict) and \"id\" in data and data[\"id\"] == id:\n",
    "                            matching_file = data\n",
    "                            #Found a match, no need to continue searching\n",
    "                            break  \n",
    "\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error decoding JSON in {file_path}\")\n",
    "\n",
    "        #If a match was found\n",
    "        if matching_file:\n",
    "            break  \n",
    "\n",
    "    if matching_file == False:\n",
    "        raise Exception(f\"Unable to find id {id}\")\n",
    "\n",
    "    return matching_file\n",
    "\n",
    "#Get all procedures (for when procedure is not set in .env)\n",
    "def all_procedures ():\n",
    "    #Path to procedure directories\n",
    "    path_procedure = \"./data/procedures\"\n",
    "\n",
    "    #Initialise array\n",
    "    all_ids = []\n",
    "\n",
    "    #For each file in the directory\n",
    "    for root, dirs, files in os.walk(path_procedure):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                #Open each json file\n",
    "                with open(file_path, \"r\") as json_file:\n",
    "                    try:\n",
    "                        data = json.load(json_file)\n",
    "\n",
    "                        #get the id value of each procedure\n",
    "                        if isinstance(data, dict) and \"id\" in data:\n",
    "                            all_ids.append(data[\"id\"])\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error decoding JSON in {file_path}\")\n",
    "\n",
    "    return all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert age object into sql\n",
    "def process_age (age):\n",
    "    if age == \"Adult\":\n",
    "        return \"age > 16 \"\n",
    " \n",
    "    elif age == \"Child\":\n",
    "        return \"age <= 16 \"\n",
    "    \n",
    "    else:\n",
    "        raise Exception (f\"Age not recognised: {age}\")\n",
    "\n",
    "#Convert the POD object into sql\n",
    "def process_pod (pod):\n",
    "    #Convert array of pod values into sql syntax set\n",
    "    sql_str = \"POD IN \" +  \"('\" + \"', '\".join(pod) + \"') \"\n",
    "\n",
    "    return sql_str\n",
    "\n",
    "#Convert the TFC object into sql\n",
    "def process_tfc (tfc):\n",
    "\n",
    "    #Convert tfc into array of strings as join only works on strings\n",
    "    tfc = [str(i) for i in tfc]\n",
    "\n",
    "    #Convert array of tfc values into sql syntax set\n",
    "    sql_str = \"tfc IN \" +  \"('\" + \"', '\".join(tfc) + \"') \"\n",
    "\n",
    "    return sql_str\n",
    "\n",
    "#Convert the MainSpec object into sql\n",
    "def process_mainspec (mainspec):\n",
    "\n",
    "    #Convert tfc into array of strings as join only works on strings\n",
    "    mainspec = [str(i) for i in mainspec]\n",
    "\n",
    "    #Convert array of tfc values into sql syntax set\n",
    "    sql_str = \"main_spec IN \" +  \"('\" + \"', '\".join(mainspec) + \"') \"\n",
    "\n",
    "    return sql_str\n",
    "\n",
    "#Handle the speciality object\n",
    "def process_speciality (speciality):\n",
    "\n",
    "    clauses_speciality = []\n",
    "\n",
    "    if 'TFC' in speciality:\n",
    "        clauses_speciality.append(process_tfc(speciality[\"TFC\"]))\n",
    "\n",
    "    if 'MainSpec' in speciality:\n",
    "        clauses_speciality.append(process_mainspec(speciality[\"MainSpec\"]))\n",
    "\n",
    "    if len(clauses_speciality) == 2:\n",
    "        return f\"({clauses_speciality[0]} OR {clauses_speciality[1]}) \"\n",
    "    else:\n",
    "        return clauses_speciality[0]\n",
    "\n",
    "#Convert variables in the logic eq into sql to be used\n",
    "def var_to_sql (var, cgs):\n",
    "    #Get variable information\n",
    "    cg_id = var[\"cg\"]\n",
    "    action = var[\"action\"]\n",
    "    type = var[\"type\"]\n",
    "    l_first = var[\"level\"][\"first\"]\n",
    "    l_last = var[\"level\"][\"last\"]\n",
    "\n",
    "    #Initialise sql string\n",
    "    if action == \"out\":\n",
    "        sql_str = \"NOT ( \"\n",
    "    else:\n",
    "        sql_str = \"( \"\n",
    "\n",
    "    #Get codes from codegroup\n",
    "    try:\n",
    "        cg_set = cgs[str(cg_id)]\n",
    "    except:\n",
    "        raise Exception(f\"Codegroup not found: {cg_id}\")\n",
    "\n",
    "\n",
    "    #Rules for codes in all columns\n",
    "    if l_first == 0:\n",
    "\n",
    "        #Convert codegroups into array\n",
    "        cg_arr = ast.literal_eval(cg_set)\n",
    "\n",
    "        #Set name of all codes column from codegroup type\n",
    "        col = f\"{type}_all\"\n",
    "\n",
    "        #Iterate through codegroup\n",
    "        items = len(cg_arr)\n",
    "        for idx, cg in enumerate(cg_arr):\n",
    "            sql_str += f\"{col} LIKE '%{cg}%' \"\n",
    "\n",
    "            #For all items that are not the final element\n",
    "            if idx != items - 1:\n",
    "                sql_str += \"OR \"\n",
    "            else:\n",
    "                sql_str += \") \"\n",
    "\n",
    "    #Rules for codes in specific columns\n",
    "    elif l_first <= l_last:\n",
    "\n",
    "        #Calculate parameters for substring query\n",
    "        #Starting point of the _all code column\n",
    "        idx_ss = 1 + (4 * (l_first-1))\n",
    "\n",
    "        #Number of columns (per 4 characters) to check\n",
    "        idx_sl = 4 * (l_last - (l_first - 1))\n",
    "        \n",
    "        #Convert codegroups into array\n",
    "        cg_arr = ast.literal_eval(cg_set)\n",
    "\n",
    "        #Set name of all codes column from codegroup type\n",
    "        col = f\"{type}_all\"\n",
    "\n",
    "        #Iterate through codegroup\n",
    "        items = len(cg_arr)\n",
    "        for idx, cg in enumerate(cg_arr):\n",
    "            sql_str += f\"SUBSTRING({col}, {idx_ss}, {idx_sl}) LIKE '%{cg}%' \"\n",
    "\n",
    "            #For all items that are not the final element\n",
    "            if idx != items - 1:\n",
    "                sql_str += \"OR \"\n",
    "            else:\n",
    "                sql_str += \") \"\n",
    "                \n",
    "    else:\n",
    "        raise Exception (f\"Invalid levels specified: from {l_first} to {l_last}\")\n",
    "    \n",
    "    return sql_str\n",
    "\n",
    "#Convert logic object into sql\n",
    "def process_logic (logic, cgs):\n",
    "    #Split logic by spaces\n",
    "    items = logic[\"eq\"].split(\" \")\n",
    "\n",
    "    #Initial sql for the logic section\n",
    "    query_logic = \"( \"\n",
    "\n",
    "    #For each word in the logic\n",
    "    for item in items:\n",
    "        #Identify keywords that are left as is\n",
    "        if item not in (\"AND\", \"OR\", \"(\", \")\"):\n",
    "            try:\n",
    "                #Get the variable object\n",
    "                variable = logic[item]\n",
    "\n",
    "                #Get the SQL to handle this variable\n",
    "                query_logic += var_to_sql(variable, cgs)\n",
    "\n",
    "            except:\n",
    "                raise Exception (f\"Error: Unable to process {item}\")\n",
    "        else:\n",
    "            #Leave keyword as is (Add whitespace to end)\n",
    "            query_logic += item + \" \"\n",
    "\n",
    "    query_logic += \") \"\n",
    "\n",
    "    return query_logic \n",
    "\n",
    "#Convert the conditions parent object into a WHERE clause for the query\n",
    "def procedure_where (conditions, cgs):\n",
    "    \n",
    "    #Build an array of clauses that are combined into the WHERE clause\n",
    "    clauses = []\n",
    "\n",
    "    #Age conditions\n",
    "    if 'Age' in conditions:\n",
    "        clauses.append(process_age(conditions[\"Age\"]))\n",
    "\n",
    "    #Point of Delivery conditions\n",
    "    if 'POD' in conditions:\n",
    "        clauses.append(process_pod(conditions[\"POD\"]))\n",
    "\n",
    "    #Speciality conditions\n",
    "    if 'Speciality' in conditions:\n",
    "        clauses.append(process_speciality(conditions[\"Speciality\"]))\n",
    "\n",
    "    #Codegroup Logic Conditions\n",
    "    if 'logic' in conditions:\n",
    "        clauses.append(process_logic(conditions[\"logic\"], cgs))\n",
    "\n",
    "    #Build WHERE clause\n",
    "    if len(clauses) > 0:\n",
    "        return \"WHERE \" + \"AND \".join(clauses)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "#Code for building the procedure query\n",
    "def build_procedure_query(json_pro, query_base, cgs):\n",
    "\n",
    "        #Derrive where clause\n",
    "        query_where = procedure_where(json_pro[\"conditions\"], cgs)\n",
    "        \n",
    "        #Return the query\n",
    "        return query_base + query_where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently unused as planning to use reference table for procedures\n",
    "def stamp_procedure_info(df, json_pro):\n",
    "    df[\"id_pro\"] = json_pro[\"id\"]\n",
    "    df[\"name\"] = json_pro[\"name\"]\n",
    "    df[\"priority\"] = json_pro[\"priority\"]\n",
    "    df[\"HVLC\"] = json_pro[\"HVLC\"]\n",
    "    df[\"benchmark\"] = json_pro[\"benchmark\"]\n",
    "\n",
    "#Build the delete query\n",
    "def build_delete_query(schema, table, fin_year, fin_month, id_pro):\n",
    "    query_del = f\"DELETE FROM {schema}.{table} WHERE id_pro = {id_pro}\\n\"\n",
    "\n",
    "    if fin_year != []:\n",
    "        #Convert array to set format\n",
    "        year_set = array_to_set(fin_year)\n",
    "        #Build where clause\n",
    "        query_del += f\"AND Year IN {year_set}\\n\"\n",
    "\n",
    "    if fin_month != []:\n",
    "        #Convert array to set format\n",
    "        month_set = array_to_set(fin_month)\n",
    "        #Build where clause\n",
    "        query_del += f\"AND Fin_Month IN {month_set}\\n\"\n",
    "\n",
    "    return query_del\n",
    "\n",
    "#Delete the exisitng data from the table with the execution scope\n",
    "def delete_existing(engine, schema, table, fin_year, fin_month, id_pro):\n",
    "\n",
    "    #Get query\n",
    "    query_del = build_delete_query(schema, table, fin_year, fin_month, id_pro)\n",
    "\n",
    "    #Execute\n",
    "    snips.execute_query(engine, query_del)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function for the procedure code\n",
    "def main ():\n",
    "    #Import settings\n",
    "    settings = import_settings()\n",
    "\n",
    "    #Load base table\n",
    "    query_base = load_ref_base (settings[\"FIN_YEAR\"], settings[\"FIN_MONTH\"])\n",
    "\n",
    "    #Load codegroups\n",
    "    with open(\"./data/codegroups.json\", \"r\") as cg_file:\n",
    "        codegroups = json.load(cg_file)\n",
    "\n",
    "    #Load the list of procedures\n",
    "    if settings[\"PROCEDURES\"] == []:\n",
    "        procedures = all_procedures()\n",
    "    else:\n",
    "        procedures = settings[\"PROCEDURES\"]\n",
    "\n",
    "    procedures.sort()\n",
    "\n",
    "    #Iterate through procedures\n",
    "    for id_pro in procedures:\n",
    "\n",
    "        #Load the procedure\n",
    "        json_pro = find_procedure(int(id_pro))\n",
    "\n",
    "        #Build the procedure query\n",
    "        query_pro = build_procedure_query(json_pro, query_base, codegroups)\n",
    "\n",
    "        #Run the query\n",
    "        engine = snips.connect(settings[\"SQL_ADDRESS\"], settings[\"SQL_DATABASE\"])\n",
    "        res = snips.execute_sfw(engine, query_pro)\n",
    "\n",
    "        #Add the priority value to the dataframe\n",
    "        #stamp_procedure_info(res, json_pro)\n",
    "        res[\"id_pro\"] = id_pro\n",
    "\n",
    "        #Delete existing data for this scope\n",
    "        delete_existing(engine, settings[\"SQL_SCHEMA\"], settings[\"SQL_TABLE\"], settings[\"FIN_YEAR\"], settings[\"FIN_MONTH\"], id_pro)\n",
    "\n",
    "        #Export results\n",
    "        if settings[\"OUTPUT\"] == \"sql\":\n",
    "            snips.upload_to_sql(res, engine, settings[\"SQL_TABLE\"], settings[\"SQL_SCHEMA\"], False, chunks=500)\n",
    "        elif settings[\"OUTPUT\"] == \"csv\":\n",
    "            if os.path.isfile(\"./output/output.csv\"):\n",
    "                res.to_csv(\"output/output.csv\", index=False, header=False, mode=\"a\")\n",
    "            else:\n",
    "                res.to_csv(\"output/output.csv\", index=False, header=True, mode=\"a\")\n",
    "            \n",
    "\n",
    "\n",
    "        #Log progress\n",
    "        print(f\"Progress: {id_pro} - {json_pro['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
