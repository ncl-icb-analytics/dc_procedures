{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import ncl.sqlsnippets as snips\n",
    "import os\n",
    "\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import runtime settings from .env file\n",
    "def import_settings():\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    return {\n",
    "        \"SQL_ADDRESS\": getenv(\"SQL_ADDRESS\"),\n",
    "        \"SQL_DATABASE\": getenv(\"SQL_DATABASE\"),\n",
    "        \"SQL_SCHEMA\": getenv(\"SQL_SCHEMA\"),\n",
    "        \"SQL_PROC_TABLE\": getenv(\"SQL_PROC_TABLE\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a given procedure\n",
    "def find_procedure (id):\n",
    "    path_procedure = \"./data/procedures\"\n",
    "\n",
    "    #Initalise match\n",
    "    matching_file = False\n",
    "\n",
    "    #For each file in the procedure directory\n",
    "    for root, dirs, files in os.walk(path_procedure):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                #Open the json file\n",
    "                with open(file_path, \"r\") as json_file:\n",
    "                    try:\n",
    "                        #Load the data\n",
    "                        data = json.load(json_file)\n",
    "\n",
    "                        #Check if it contains the id\n",
    "                        if isinstance(data, dict) and \"id\" in data and data[\"id\"] == id:\n",
    "                            matching_file = data\n",
    "                            #Found a match, no need to continue searching\n",
    "                            break  \n",
    "\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error decoding JSON in {file_path}\")\n",
    "\n",
    "        #If a match was found\n",
    "        if matching_file:\n",
    "            break  \n",
    "\n",
    "    if matching_file == False:\n",
    "        raise Exception(f\"Unable to find id {id}\")\n",
    "\n",
    "    return matching_file\n",
    "\n",
    "#Get all procedures (for when procedure is not set in .env)\n",
    "def all_procedures ():\n",
    "    #Path to procedure directories\n",
    "    path_procedure = \"./data/procedures\"\n",
    "\n",
    "    #Initialise array\n",
    "    all_ids = []\n",
    "\n",
    "    #For each file in the directory\n",
    "    for root, dirs, files in os.walk(path_procedure):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                #Open each json file\n",
    "                with open(file_path, \"r\") as json_file:\n",
    "                    try:\n",
    "                        data = json.load(json_file)\n",
    "\n",
    "                        #get the id value of each procedure\n",
    "                        if isinstance(data, dict) and \"id\" in data:\n",
    "                            all_ids.append(data[\"id\"])\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error decoding JSON in {file_path}\")\n",
    "\n",
    "    return all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all procedure ids\n",
    "procedures = all_procedures()\n",
    "\n",
    "\n",
    "# Create empty lists to store data\n",
    "ids = []\n",
    "names = []\n",
    "speciality_areas = []\n",
    "HVLCs = []\n",
    "priorities = []\n",
    "benchmarks = []\n",
    "\n",
    "#For each procedure\n",
    "for id in procedures:\n",
    "\n",
    "    #Get the JSON\n",
    "    data = find_procedure(id)\n",
    "\n",
    "    # Extract values from the JSON and append to the lists\n",
    "    ids.append(data[\"id\"])\n",
    "    names.append(data[\"name\"])\n",
    "    speciality_areas.append(data[\"speciality_area\"])\n",
    "    HVLCs.append(data[\"HVLC\"])\n",
    "    priorities.append(data[\"priority\"])\n",
    "\n",
    "    if \"benchmark\" in data:\n",
    "        benchmarks.append(data[\"benchmark\"])\n",
    "    else:\n",
    "        benchmarks.append(None)\n",
    "\n",
    "# Create a dictionary from the lists\n",
    "data_dict = {\n",
    "    \"id\": ids,\n",
    "    \"name\": names,\n",
    "    \"speciality_area\": speciality_areas,\n",
    "    \"HVLC\": HVLCs,\n",
    "    \"priority\": priorities,\n",
    "    \"benchmark\": benchmarks\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.sort_values(by=['id'], ascending=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = import_settings()\n",
    "engine = snips.connect(settings[\"SQL_ADDRESS\"], settings[\"SQL_DATABASE\"])\n",
    "\n",
    "snips.upload_to_sql(df, engine, settings[\"SQL_PROC_TABLE\"], settings[\"SQL_SCHEMA\"], replace=True, chunks=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
